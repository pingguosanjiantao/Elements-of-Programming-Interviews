现在社会的数据集合是非常大的。例如一个流行的社交网络估计包含2万亿的不同元素。
那怎样对一个有10亿的1000字节的字符串进行排序呢？如果是1万亿的呢？
*提示 1万亿1000字节的字符串能在一个机子上运行吗？*
答：10亿1000字节的字符串在一个单机的RAM上不能满足，但是在单机的硬盘上是可以的。
因此，可以把数据分成小块在RAM中排序，再把数据写回硬盘，然后再合并这些排好序的数据块。
数据块的合并我们可以参照11.1.
UNIX排序在对大文件排序时就是使用这些规则，并且比基于上述基于合并算法的直接实现要快。
如果数据是由1万亿的1000字节的string组成，那么单机肯定不能满足，这必须在集群中分布。
目前此场景下使用最多的是把数据组织起来，这样的话二分查找可以有较好的效果。
对数据集中的每个元素进行排序是不够的，这是因为不能达到一个全局排序——这样的话需要再每个机子上进行二分查找。
较直接的一个方法是用一个机子合并排序后的数据集，但是，这个机器可能成为瓶颈。
一个解决瓶颈问题的方法是首先对数据重新排序，这样的话第i个机子可以把字符串存储在一个区间内，
例如机器3负责daily和ending之间的字符串。
区间——机器这样映射R可以通过对每个文件的取样和取样数据排序计算得到。
如果取样的子集足够小，那么它可以在单机上进行排序。
这种方法可以参照12.8，可以用于分配机器的哪个区间。
使A为取样字符串的排序数组。
假设有M台机器，定义ri=iA[n/M],其中n是A的长度。
机器i负责处理区间[ri,ri+1]，如果分布式数据是优先的，例如，标准的，那取样这步可以略过。
重排序可以以一个完全的分布式执行，每个机器通过遍历自己负责的字符串实现。
在重排序后，每个机器将自己存储的字符串排好序，接着搜索可以使用R来解决去哪个机器查找。


