Jingle正在开发一个时事新闻的新功能。在Jingle的一个单机上手机得到已给在线的新闻标题，包括报纸、实事专栏、博客等。
差不多每分钟有一千个标题，每个标题大概100kb。
Jingle会用一个有着1000台服务器的数据中心对外提供这些标题服务。
为了性能的考虑，每个服务器必须存储新增的标题副本。数据中心的机器离收集机器庭挺远的。
设计一个高效的方法：从单机拷贝这一千个文件到1000个服务器，每个文件100kb

假设单机的带宽受限，那么首先要做一个小小的优化，比如把标题串成一个文件，然后压缩这个文件。
打开1000个单机与1000个机器的链接，然后传送标题，这个方法是不可行的。这是因为总的数据大小接近100gb。
由于数据中心机器之间的带宽是很高的，我们可以从单机先拷贝到一个机器，然后用这个机器复制到其他机器。
为了避免单个机器服务999个机器，我们可以让完成拷贝的机器复制到那些还没拷贝的机器。
这样的话，拷贝时间将指数级的减少。
还有一些小事情可以优化下。
一个机器在收到整个文件前怎样开始拷贝给其他机器（这是很难的，应该考虑到链路或者服务的中断）。
那些没被拷贝的机器的信息如何共享？（需要有一个中央仓库或者服务器可以用来检查和随机选择）
机器之间的带宽不是一个常量，机器该如何选择？（相邻的机器，例如，在相同机架内的应该优先链接）
最后，应该有很多的开源方案，例如Unison，BitTorrent。